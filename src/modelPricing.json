{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "description": "Model pricing data - costs per million tokens for input and output",
  "metadata": {
    "lastUpdated": "2026-01-15",
    "sources": [
      {
        "name": "OpenAI API Pricing",
        "url": "https://openai.com/api/pricing/",
        "retrievedDate": "2025-12-27"
      },
      {
        "name": "Anthropic Claude Pricing",
        "url": "https://www.anthropic.com/pricing",
        "note": "Standard rates"
      },
      {
        "name": "Google AI Gemini API Pricing",
        "url": "https://ai.google.dev/pricing",
        "retrievedDate": "2025-12-27"
      },
      {
        "name": "GitHub Copilot Supported Models",
        "url": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
        "retrievedDate": "2025-12-27"
      }
    ],
    "disclaimer": "GitHub Copilot uses these models but pricing may differ from direct API usage. These are reference prices for cost estimation purposes only."
  },
  "pricing": {
    "gpt-5": {
      "inputCostPerMillion": 1.25,
      "outputCostPerMillion": 10.0,
      "category": "GPT-5 models"
    },
    "gpt-5-codex": {
      "inputCostPerMillion": 1.25,
      "outputCostPerMillion": 10.0,
      "category": "GPT-5 models"
    },
    "gpt-5-mini": {
      "inputCostPerMillion": 0.25,
      "outputCostPerMillion": 2.0,
      "category": "GPT-5 models"
    },
    "gpt-5.1": {
      "inputCostPerMillion": 1.25,
      "outputCostPerMillion": 10.0,
      "category": "GPT-5 models"
    },
    "gpt-5.1-codex": {
      "inputCostPerMillion": 1.25,
      "outputCostPerMillion": 10.0,
      "category": "GPT-5 models"
    },
    "gpt-5.1-codex-max": {
      "inputCostPerMillion": 1.75,
      "outputCostPerMillion": 14.0,
      "category": "GPT-5 models"
    },
    "gpt-5.1-codex-mini": {
      "inputCostPerMillion": 0.25,
      "outputCostPerMillion": 2.0,
      "category": "GPT-5 models"
    },
    "gpt-5.2": {
      "inputCostPerMillion": 1.75,
      "outputCostPerMillion": 14.0,
      "category": "GPT-5 models"
    },
    "gpt-5.2-codex": {
      "inputCostPerMillion": 1.75,
      "outputCostPerMillion": 14.0,
      "category": "GPT-5 models"
    },
    "gpt-4": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 12.0,
      "category": "GPT-4 models"
    },
    "gpt-4.1": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 12.0,
      "category": "GPT-4 models"
    },
    "gpt-4.1-mini": {
      "inputCostPerMillion": 0.8,
      "outputCostPerMillion": 3.2,
      "category": "GPT-4 models"
    },
    "gpt-4o": {
      "inputCostPerMillion": 2.5,
      "outputCostPerMillion": 10.0,
      "category": "GPT-4 models"
    },
    "gpt-4o-mini": {
      "inputCostPerMillion": 0.15,
      "outputCostPerMillion": 0.6,
      "category": "GPT-4 models"
    },
    "claude-sonnet-3.5": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 15.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-sonnet-3.7": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 15.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-sonnet-4": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 15.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-sonnet-4.5": {
      "inputCostPerMillion": 3.0,
      "outputCostPerMillion": 15.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-haiku": {
      "inputCostPerMillion": 0.25,
      "outputCostPerMillion": 1.25,
      "category": "Claude models (Anthropic)"
    },
    "claude-haiku-4.5": {
      "inputCostPerMillion": 1.0,
      "outputCostPerMillion": 5.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-opus-4.1": {
      "inputCostPerMillion": 15.0,
      "outputCostPerMillion": 75.0,
      "category": "Claude models (Anthropic)"
    },
    "claude-opus-4.5": {
      "inputCostPerMillion": 5.0,
      "outputCostPerMillion": 25.0,
      "category": "Claude models (Anthropic)"
    },
    "o3-mini": {
      "inputCostPerMillion": 4.0,
      "outputCostPerMillion": 16.0,
      "category": "OpenAI reasoning models"
    },
    "o4-mini": {
      "inputCostPerMillion": 4.0,
      "outputCostPerMillion": 16.0,
      "category": "OpenAI reasoning models"
    },
    "gpt-3.5-turbo": {
      "inputCostPerMillion": 0.5,
      "outputCostPerMillion": 1.5,
      "category": "Legacy models"
    },
    "gemini-2.5-pro": {
      "inputCostPerMillion": 1.25,
      "outputCostPerMillion": 10.0,
      "category": "Google Gemini models"
    },
    "gemini-3-flash": {
      "inputCostPerMillion": 0.50,
      "outputCostPerMillion": 3.0,
      "category": "Google Gemini models"
    },
    "gemini-3-pro": {
      "inputCostPerMillion": 2.0,
      "outputCostPerMillion": 12.0,
      "category": "Google Gemini models"
    },
    "gemini-3-pro-preview": {
      "inputCostPerMillion": 2.0,
      "outputCostPerMillion": 12.0,
      "category": "Google Gemini models"
    },
    "grok-code-fast-1": {
      "inputCostPerMillion": 0.20,
      "outputCostPerMillion": 1.50,
      "category": "xAI Grok models"
    },
    "raptor-mini": {
      "inputCostPerMillion": 0.25,
      "outputCostPerMillion": 2.0,
      "category": "GitHub Copilot fine-tuned models"
    }
  }
}
